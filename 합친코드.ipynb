{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap-learn\n",
      "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting hdbscan\n",
      "  Downloading hdbscan-0.8.40-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from umap-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from umap-learn) (1.10.1)\n",
      "Collecting scikit-learn>=0.22 (from umap-learn)\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from umap-learn) (4.67.1)\n",
      "Collecting joblib>=1.0 (from hdbscan)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: filelock in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.2->umap-learn)\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from numba>=0.51.2->umap-learn) (8.5.0)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.22->umap-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51.2->umap-learn) (3.21.0)\n",
      "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
      "Downloading hdbscan-0.8.40-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, safetensors, regex, llvmlite, joblib, scikit-learn, numba, tokenizers, pynndescent, hdbscan, umap-learn, transformers\n",
      "Successfully installed hdbscan-0.8.40 joblib-1.4.2 llvmlite-0.41.1 numba-0.58.1 pynndescent-0.5.13 regex-2024.11.6 safetensors-0.4.5 scikit-learn-1.3.2 threadpoolctl-3.5.0 tokenizers-0.20.3 transformers-4.46.3 umap-learn-0.5.7\n"
     ]
    }
   ],
   "source": [
    "!pip install umap-learn hdbscan transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kwy00/song\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-04 19:43:55.740314: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-04 19:43:55.741521: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-04 19:43:55.764284: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-04 19:43:55.764728: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-04 19:43:56.119204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: '/home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import skimage\n",
    "import umap\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 설정\n",
    "BATCH_SIZE = 8  # RTX 3080 10GB 메모리에 맞게 조정\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정 제안\n",
    "BATCH_SIZE = 8  # RTX 3080 10GB에 최적화\n",
    "IMAGE_SIZE = 256  # 이미지 크기 명시\n",
    "NUM_WORKERS = 8 # 데이터 로딩 최적화\n",
    "PIN_MEMORY = True  # GPU 메모리 전송 최적화\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(glob('/home/kwy00/song/lama-with-refiner/extracted_files/train_gt/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polygenerator\n",
      "  Downloading polygenerator-0.2.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting lightning\n",
      "  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting segmentation-models-pytorch\n",
      "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2023.10.0)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
      "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from lightning) (1.24.4)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from lightning) (24.2)\n",
      "Requirement already satisfied: torch<4.0,>=2.0.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from lightning) (2.4.1)\n",
      "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
      "  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from lightning) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from lightning) (4.12.2)\n",
      "Collecting pytorch-lightning (from lightning)\n",
      "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.19.1)\n",
      "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting timm==0.9.2 (from segmentation-models-pytorch)\n",
      "  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n",
      "Requirement already satisfied: pillow in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from segmentation-models-pytorch) (10.4.0)\n",
      "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: huggingface-hub in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.26.3)\n",
      "Requirement already satisfied: safetensors in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.5)\n",
      "Requirement already satisfied: requests in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2.32.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10.11)\n",
      "Requirement already satisfied: setuptools in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
      "Requirement already satisfied: filelock in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (3.16.1)\n",
      "Requirement already satisfied: sympy in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.0.0->lightning) (12.6.85)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from jinja2->torch<4.0,>=2.0.0->lightning) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from sympy->torch<4.0,>=2.0.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.0)\n",
      "Downloading polygenerator-0.2.0-py2.py3-none-any.whl (5.8 kB)\n",
      "Downloading lightning-2.3.3-py3-none-any.whl (808 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
      "Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Downloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=fdf3076d7149726b23db8684aa4c93d576535cc2f860f6b9946fbdb5c9e87a83\n",
      "  Stored in directory: /home/kwy00/.cache/pip/wheels/84/b9/90/25a0195cf95fb5533db96f1c77ea3f296b7cc86ae8ae48e3dc\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=cd10ffc8f95a267a909bab469f5028f818215a7efc869fb740d289f2ca1530d7\n",
      "  Stored in directory: /home/kwy00/.cache/pip/wheels/ed/fa/b9/5c82b59d905f95542a192b883c0cc0082407ea2f54beb2f9e6\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\n",
      "Installing collected packages: polygenerator, munch, lightning-utilities, torchmetrics, efficientnet-pytorch, timm, pytorch-lightning, pretrainedmodels, segmentation-models-pytorch, lightning\n",
      "Successfully installed efficientnet-pytorch-0.7.1 lightning-2.3.3 lightning-utilities-0.11.9 munch-4.0.0 polygenerator-0.2.0 pretrainedmodels-0.7.4 pytorch-lightning-2.4.0 segmentation-models-pytorch-0.3.3 timm-0.9.2 torchmetrics-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install polygenerator lightning segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import zipfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from polygenerator import (\n",
    "    random_polygon,\n",
    "    random_star_shaped_polygon,\n",
    "    random_convex_polygon,\n",
    ")\n",
    "from sklearn.model_selection import KFold\n",
    "from skimage.metrics import structural_similarity as ski_ssim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_image(image, min_polygon_bbox_size=50):\n",
    "    # 입력 이미지의 크기 가져오기\n",
    "    width, height = image.size\n",
    "\n",
    "    while True:\n",
    "        # 랜덤한 바운딩 박스 좌표 생성\n",
    "        bbox_x1 = random.randint(0, width-min_polygon_bbox_size)\n",
    "        bbox_y1 = random.randint(0, height-min_polygon_bbox_size)\n",
    "        bbox_x2 = random.randint(bbox_x1, width)  # x1보다 큰 x2 좌표\n",
    "        bbox_y2 = random.randint(bbox_y1, height)  # y1보다 큰 y2 좌표\n",
    "\n",
    "        # 바운딩 박스가 최소 크기보다 작으면 다시 생성\n",
    "        if (bbox_x2-bbox_x1)<min_polygon_bbox_size or (bbox_y2-bbox_y1)<min_polygon_bbox_size:\n",
    "            continue\n",
    "\n",
    "        # 바운딩 박스 정보 저장\n",
    "        mask_bbox = [bbox_x1, bbox_y1, bbox_x2, bbox_y2]\n",
    "        mask_width = bbox_x2-bbox_x1\n",
    "        mask_height = bbox_y2-bbox_y1\n",
    "\n",
    "        # 랜덤한 다각형 생성을 위한 설정\n",
    "        num_points = random.randint(3,20)  # 3~20개의 꼭지점\n",
    "        # 다각형 생성 함수 랜덤 선택\n",
    "        polygon_func = random.choice([\n",
    "            random_polygon,\n",
    "            random_star_shaped_polygon,\n",
    "            random_convex_polygon\n",
    "        ])\n",
    "\n",
    "        # 0~1 스케일로 다각형 생성 후 실제 크기로 변환\n",
    "        polygon = polygon_func(num_points=num_points) #scaled 0~1\n",
    "        polygon = [(round(r*mask_width), round(c*mask_height)) for r,c in polygon]\n",
    "\n",
    "        # 다각형 마스크 생성\n",
    "        polygon_mask = skimage.draw.polygon2mask((mask_width, mask_height), polygon)\n",
    "\n",
    "        # 다각형 크기가 최소 크기 조건을 만족하면 루프 종료\n",
    "        if np.sum(polygon_mask)>(min_polygon_bbox_size//2)**2:\n",
    "            break\n",
    "\n",
    "    # 전체 이미지 크기의 마스크 생성\n",
    "    full_image_mask = np.zeros((width, height), dtype=np.uint8)\n",
    "    full_image_mask[bbox_x1:bbox_x2, bbox_y1:bbox_y2] = polygon_mask\n",
    "\n",
    "    # 그레이스케일 이미지 생성 및 마스크 적용\n",
    "    image_gray = image.convert('L')  # RGB를 그레이스케일로 변환\n",
    "    image_gray_array = np.array(image_gray)\n",
    "    random_color = random.randint(0, 255)  # 랜덤한 그레이스케일 값 생성\n",
    "    # 마스크 영역에 랜덤 색상 적용\n",
    "    image_gray_array[full_image_mask == 1] = random_color\n",
    "    image_gray_masked = Image.fromarray(image_gray_array)\n",
    "\n",
    "    # 결과 반환\n",
    "    return {\n",
    "        'image_gt': image,               # 원본 이미지\n",
    "        'mask': full_image_mask,         # 생성된 마스크\n",
    "        'image_gray': image_gray,        # 그레이스케일 이미지\n",
    "        'image_gray_masked': image_gray_masked  # 마스크가 적용된 그레이스케일 이미지\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ssim_score(true, pred):\n",
    "    # 전체 RGB 이미지를 사용해 SSIM 계산 (channel_axis=-1)\n",
    "    ssim_value = ski_ssim(true, pred, channel_axis=-1, data_range=pred.max() - pred.min())\n",
    "    return ssim_value\n",
    "\n",
    "def get_masked_ssim_score(true, pred, mask):\n",
    "    # 손실 영역의 좌표에서만 RGB 채널별 픽셀 값 추출\n",
    "    true_masked_pixels = true[mask > 0]\n",
    "    pred_masked_pixels = pred[mask > 0]\n",
    "\n",
    "    # 손실 영역 픽셀만으로 SSIM 계산 (채널축 사용)\n",
    "    ssim_value = ski_ssim(\n",
    "        true_masked_pixels,\n",
    "        pred_masked_pixels,\n",
    "        channel_axis=-1,\n",
    "        data_range=pred.max() - pred.min()\n",
    "    )\n",
    "    return ssim_value\n",
    "\n",
    "def get_histogram_similarity(true, pred, cvt_color=cv2.COLOR_RGB2HSV):\n",
    "    # BGR 이미지를 HSV로 변환\n",
    "    true_hsv = cv2.cvtColor(true, cvt_color)\n",
    "    pred_hsv = cv2.cvtColor(pred, cvt_color)\n",
    "\n",
    "    # H 채널에서 히스토그램 계산 및 정규화\n",
    "    hist_true = cv2.calcHist([true_hsv], [0], None, [180], [0, 180])\n",
    "    hist_pred = cv2.calcHist([pred_hsv], [0], None, [180], [0, 180])\n",
    "    hist_true = cv2.normalize(hist_true, hist_true).flatten()\n",
    "    hist_pred = cv2.normalize(hist_pred, hist_pred).flatten()\n",
    "\n",
    "    # 히스토그램 간 유사도 계산 (상관 계수 사용)\n",
    "    similarity = cv2.compareHist(hist_true, hist_pred, cv2.HISTCMP_CORREL)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험의 재현성을 위한 랜덤 시드 설정\n",
    "SEED = 42\n",
    "# K-fold 교차 검증을 위한 분할 수\n",
    "N_SPLIT = 5\n",
    "# 모델 학습시 한 번에 처리할 데이터 개수\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 8  # Ryzen 5800x의 코어 수를 고려\n",
    "PIN_MEMORY = True  # GPU 메모리 전송 최적화\n",
    "# 이미지 전처리를 위한 정규화 파라미터\n",
    "# 일반적으로 ImageNet 데이터셋의 평균과 표준편차 값을 사용\n",
    "IMAGE_PREPROC_MEAN = 0.5    # 이미지 픽셀값의 평균\n",
    "IMAGE_PREPROC_STD = 0.225   # 이미지 픽셀값의 표준편차\n",
    "\n",
    "# 다각형 마스크 생성시 최소 바운딩 박스 크기\n",
    "MIN_POLYGON_BBOX_SIZE = 64  # 픽셀 단위\n",
    "\n",
    "# 학습 관련 파라미터 (새로 추가)\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "TRAIN_DATA_DIR = '/home/kwy00/song/lama-with-refiner/extracted_files/train_gt'  # 학습용 원본 이미지 경로\n",
    "VALID_DATA_DIR = f'/home/kwy00/song/data/valid_input/{SEED=}-{MIN_POLYGON_BBOX_SIZE=}'  # 검증 데이터 경로\n",
    "TEST_DATA_DIR = '/home/kwy00/song/lama-with-refiner/extracted_files/test_input'  # 테스트 데이터 경로\n",
    "SUBMISSON_DATA_DIR = '/home/kwy00/song/lama-with-refiner/submission'  # 제출 파일 저장 경로\n",
    "\n",
    "# 실험 설정\n",
    "EXPERIMENT_NAME = 'third'  # 현재 실험의 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/kwy00/song/train_preproc.csv')\n",
    "test_df = pd.read_csv('/home/kwy00/song/test_preproc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29603/29603 [04:11<00:00, 117.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 저장을 위한 디렉토리 생성\n",
    "os.makedirs(VALID_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# 학습 데이터프레임의 모든 이미지에 대해 반복\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    # 원본 이미지 경로 가져오기\n",
    "    img_path = train_df.iloc[idx, 0]\n",
    "    img_path = os.path.join(TRAIN_DATA_DIR, img_path)\n",
    "\n",
    "    # 저장할 파일명 생성 (TRAIN -> VALID, png -> npy로 변환)\n",
    "    save_image_name = os.path.basename(img_path).replace('TRAIN', 'VALID').replace('png','npy')\n",
    "    save_image_path = f'{VALID_DATA_DIR}/{save_image_name}'\n",
    "\n",
    "    # 이미 처리된 파일은 건너뛰기\n",
    "    if os.path.exists(save_image_path):\n",
    "        continue\n",
    "\n",
    "    # 이미지 열기 및 마스크 생성\n",
    "    image = Image.open(img_path)\n",
    "    valid_input_image = get_input_image(image, MIN_POLYGON_BBOX_SIZE)\n",
    "\n",
    "    # 생성된 데이터를 numpy 배열로 저장\n",
    "    np.save(save_image_path, valid_input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_outlier = train_df[train_df['label']==-1]\n",
    "train_df = train_df[train_df['label']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=N_SPLIT, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold 교차 검증을 위한 데이터 분할\n",
    "for fold_idx, (train_indices, valid_indices) in enumerate(kf.split(train_df['image'], train_df['label'])):\n",
    "    # 학습용 데이터와 검증용 데이터 분리\n",
    "    train_fold_df = train_df.iloc[train_indices].reset_index(drop=True)\n",
    "    valid_fold_df = train_df.iloc[valid_indices].reset_index(drop=True)\n",
    "\n",
    "    # 검증 데이터의 파일명 변환 (TRAIN -> VALID, png -> npy)\n",
    "    valid_fold_df['image'] = valid_fold_df['image'].apply(lambda x: x.replace('TRAIN', 'VALID').replace('png', 'npy'))\n",
    "\n",
    "    # 검증 속도 향상을 위해 각 레이블당 하나의 샘플만 유지\n",
    "    valid_fold_df = valid_fold_df.drop_duplicates('label')\n",
    "    # train_fold_df = pd.concat([train_fold_df,train_df_outlier],axis=0).reset_index(drop=True)\n",
    "    # 첫 번째 폴드만 사용\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kwy00/song\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: 줄 1: git: 명령어를 찾을 수 없음\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/geomagical/lama-with-refiner.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축 해제 완료: ./lama-with-refiner/predicted_masks3\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def unzip_file(zip_file_path, extract_to_path):\n",
    "    \"\"\"\n",
    "    ZIP 파일을 지정된 폴더에 압축 해제하는 함수.\n",
    "\n",
    "    Args:\n",
    "        zip_file_path (str): 압축 해제할 ZIP 파일 경로.\n",
    "        extract_to_path (str): 파일을 풀어놓을 폴더 경로.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # ZIP 파일 열기\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # 압축 해제\n",
    "        zip_ref.extractall(extract_to_path)\n",
    "    print(f\"압축 해제 완료: {extract_to_path}\")\n",
    "\n",
    "# 사용 예시\n",
    "zip_file_path = \"/home/kwy00/song/predicted_mask3.zip\"\n",
    "extract_to_path =\"./lama-with-refiner/predicted_masks3\"\n",
    "unzip_file(zip_file_path, extract_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, data_dir='/home/kwy00/song/content/extracted_files/train_gt', mode='train',mask_dir = \"/home/kwy00/song/lama-with-refiner/predicted_masks3\" ,min_polygon_bbox_size=MIN_POLYGON_BBOX_SIZE):\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.min_polygon_bbox_size = min_polygon_bbox_size\n",
    "        self.mask_dir = mask_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path and label\n",
    "        img_path = self.df.iloc[idx, 0]  # Assuming first column is the path\n",
    "        img_path = os.path.join(self.data_dir, img_path)\n",
    "\n",
    "        # Apply augmentation if in training mode\n",
    "        if self.mode == 'train':\n",
    "            image = Image.open(img_path)\n",
    "            image_input = get_input_image(image, self.min_polygon_bbox_size)\n",
    "            return image_input\n",
    "\n",
    "        elif self.mode == 'valid':\n",
    "            image_input = self.load_input_image(img_path)\n",
    "            return image_input\n",
    "        elif self.mode == 'test':\n",
    "            image = Image.open(img_path)\n",
    "            img_name = os.path.basename(img_path)\n",
    "            mask_path = os.path.join(self.mask_dir, img_name)\n",
    "            mask = Image.open(mask_path)\n",
    "            return {\n",
    "                'image_gray_masked':image,\n",
    "                'mask':mask\n",
    "            }\n",
    "\n",
    "    def load_input_image(self, img_input_path):\n",
    "        image_input = np.load(img_input_path, allow_pickle=True)\n",
    "        return image_input.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(train_fold_df, data_dir=TRAIN_DATA_DIR, mode='train')\n",
    "valid_dataset = CustomImageDataset(valid_fold_df, data_dir=VALID_DATA_DIR, mode='valid')\n",
    "test_dataset = CustomImageDataset(test_df, data_dir=TEST_DATA_DIR, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollateFn:\n",
    "    def __init__(self, mean=IMAGE_PREPROC_MEAN, std=IMAGE_PREPROC_STD, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        if self.mode =='train' or self.mode=='valid':\n",
    "            # Initialize lists to store each component of the batch\n",
    "            masks= []\n",
    "            images_gray = []\n",
    "            images_gray_masked = []\n",
    "            images_gt = []\n",
    "\n",
    "            for example in examples:\n",
    "                # Assuming each example is a dictionary with keys 'mask', 'image_gray', 'image_gray_masked', 'image_gt'\n",
    "                masks.append(example['mask'])\n",
    "                images_gray.append(self.normalize_image(example['image_gray']))\n",
    "                images_gray_masked.append(self.normalize_image(example['image_gray_masked']))\n",
    "                images_gt.append(self.normalize_image(np.array(example['image_gt'])))\n",
    "\n",
    "            return {\n",
    "                'masks': torch.from_numpy(np.stack(masks)).long(),\n",
    "                'images_gray': torch.from_numpy(np.stack(images_gray)).unsqueeze(1).float(),\n",
    "                'images_gray_masked': torch.from_numpy(np.stack(images_gray_masked)).unsqueeze(1).float(),\n",
    "                'images_gt': torch.from_numpy(np.stack(images_gt)).permute(0,3,1,2).float()\n",
    "            }\n",
    "\n",
    "        elif self.mode == 'test':\n",
    "            images_gray_masked = []\n",
    "            masks=[]\n",
    "            for example in examples:\n",
    "                images_gray_masked.append(self.normalize_image(example['image_gray_masked']))\n",
    "                masks.append(example['mask'])\n",
    "            return {\n",
    "                'images_gray_masked': torch.from_numpy(np.stack(images_gray_masked)).unsqueeze(1).float(),\n",
    "                'mask': torch.from_numpy(np.stack(masks)).long()\n",
    "            }\n",
    "\n",
    "    def normalize_image(self, image):\n",
    "        return (np.array(image)/255-self.mean)/self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kwy00/song/lama-with-refiner\n"
     ]
    }
   ],
   "source": [
    "%cd lama-with-refiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=8,  # Ryzen 5800x의 8코어 활용\n",
    "    pin_memory=True,  # GPU 메모리 전송 최적화\n",
    "    collate_fn=CollateFn(mode='train'),\n",
    "    persistent_workers=True  # 워커 재사용으로 성능 향상\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE*2,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    collate_fn=CollateFn(mode='valid'),\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE*2,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    collate_fn=CollateFn(mode='test'),\n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kwy00/song/lama-with-refiner\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: 줄 1: curl: 명령어를 찾을 수 없음\n",
      "unzip:  cannot find or open big-lama.zip, big-lama.zip.zip or big-lama.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!curl -LJO https://huggingface.co/smartywu/big-lama/resolve/main/big-lama.zip\n",
    "!unzip big-lama.zip -d ./weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-i0jt9kzj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-i0jt9kzj\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit c69939aa85460e8135f40bce908a6cddaa73065f\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from detectron2==0.6) (10.4.0)\n",
      "Requirement already satisfied: matplotlib in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from detectron2==0.6) (3.7.5)\n",
      "Collecting pycocotools>=2.0.2 (from detectron2==0.6)\n",
      "  Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting termcolor>=1.1 (from detectron2==0.6)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting tabulate (from detectron2==0.6)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting cloudpickle (from detectron2==0.6)\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from detectron2==0.6) (4.67.1)\n",
      "Collecting tensorboard (from detectron2==0.6)\n",
      "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
      "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting black (from detectron2==0.6)\n",
      "  Downloading black-24.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (78 kB)\n",
      "Requirement already satisfied: packaging in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from detectron2==0.6) (24.2)\n",
      "Requirement already satisfied: numpy in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.24.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from hydra-core>=1.1->detectron2==0.6) (6.4.5)\n",
      "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (2.9.0)\n",
      "Collecting click>=8.0.0 (from black->detectron2==0.6)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from black->detectron2==0.6) (4.3.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from black->detectron2==0.6) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from black->detectron2==0.6) (4.12.2)\n",
      "Collecting absl-py>=0.4 (from tensorboard->detectron2==0.6)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->detectron2==0.6)\n",
      "  Downloading grpcio-1.68.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard->detectron2==0.6)\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard->detectron2==0.6)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->detectron2==0.6)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf>=3.19.6 (from tensorboard->detectron2==0.6)\n",
      "  Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->detectron2==0.6)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->detectron2==0.6)\n",
      "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.44.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.21.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (8.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->detectron2==0.6) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (439 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading black-24.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading grpcio-1.68.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
      "  Building wheel for detectron2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for detectron2: filename=detectron2-0.6-cp38-cp38-linux_x86_64.whl size=6482472 sha256=1c6efb5f4340c8c2bf43fc1d5f552e85313c7d4332087d5a15d0c029bd40730b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9qqmwpjp/wheels/19/ac/65/e48e5e4ec2702274d927c5a6efb75709b24014371d3bb778f2\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=c2cc6420eff2c0b05bc765375dfa5a91e3a01c9e0214749929f2151e993db41c\n",
      "  Stored in directory: /home/kwy00/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=f2b62a05b40df6486372949f4f8ff20b9aef755a899f479f493e47e3e928eaa1\n",
      "  Stored in directory: /home/kwy00/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
      "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, yacs, werkzeug, termcolor, tensorboard-data-server, tabulate, pyasn1, protobuf, portalocker, pathspec, omegaconf, oauthlib, mypy-extensions, grpcio, cloudpickle, click, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, iopath, hydra-core, black, pycocotools, google-auth, fvcore, google-auth-oauthlib, tensorboard, detectron2\n",
      "Successfully installed absl-py-2.1.0 antlr4-python3-runtime-4.9.3 black-24.8.0 cachetools-5.5.0 click-8.1.7 cloudpickle-3.1.0 detectron2-0.6 fvcore-0.1.5.post20221221 google-auth-2.36.0 google-auth-oauthlib-1.0.0 grpcio-1.68.1 hydra-core-1.3.2 iopath-0.1.9 markdown-3.7 mypy-extensions-1.0.0 oauthlib-3.2.2 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.0.0 protobuf-5.29.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycocotools-2.0.7 requests-oauthlib-2.0.0 rsa-4.9 tabulate-0.9.0 tensorboard-2.14.0 tensorboard-data-server-0.7.2 termcolor-2.4.0 werkzeug-3.0.6 yacs-0.1.8\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: tqdm in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: numpy in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.24.3)\n",
      "Requirement already satisfied: easydict==1.9.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.9)\n",
      "Requirement already satisfied: scikit-image>=0.19.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.21.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: opencv-python in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (4.10.0.84)\n",
      "Requirement already satisfied: tensorflow in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (2.13.1)\n",
      "Requirement already satisfied: joblib in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.4.2)\n",
      "Requirement already satisfied: matplotlib in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (3.7.5)\n",
      "Requirement already satisfied: pandas in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (2.0.3)\n",
      "Requirement already satisfied: albumentations==0.5.2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.5.2)\n",
      "Requirement already satisfied: hydra-core==1.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (1.1.0)\n",
      "Requirement already satisfied: tabulate in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (0.9.0)\n",
      "Collecting kornia==0.5.0 (from -r requirements.txt (line 15))\n",
      "  Using cached kornia-0.5.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: webdataset in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (0.2.100)\n",
      "Requirement already satisfied: packaging in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (24.2)\n",
      "Requirement already satisfied: wldhx.yadisk-direct in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (0.0.6)\n",
      "Requirement already satisfied: scipy in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from albumentations==0.5.2->-r requirements.txt (line 12)) (1.10.1)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from albumentations==0.5.2->-r requirements.txt (line 12)) (0.4.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from albumentations==0.5.2->-r requirements.txt (line 12)) (4.10.0.84)\n",
      "Requirement already satisfied: omegaconf==2.1.* in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from hydra-core==1.1.0->-r requirements.txt (line 13)) (2.1.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from hydra-core==1.1.0->-r requirements.txt (line 13)) (4.8)\n",
      "Requirement already satisfied: importlib-resources in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from hydra-core==1.1.0->-r requirements.txt (line 13)) (6.4.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from kornia==0.5.0->-r requirements.txt (line 15)) (2.1.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from scikit-image>=0.19.0->-r requirements.txt (line 5)) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from scikit-image>=0.19.0->-r requirements.txt (line 5)) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from scikit-image>=0.19.0->-r requirements.txt (line 5)) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from scikit-image>=0.19.0->-r requirements.txt (line 5)) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from scikit-image>=0.19.0->-r requirements.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from scikit-image>=0.19.0->-r requirements.txt (line 5)) (0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from scikit-learn>=1.0->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.68.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (3.11.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (4.25.5)\n",
      "Requirement already satisfied: setuptools in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorflow->-r requirements.txt (line 8)) (0.34.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 10)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 11)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 11)) (2024.2)\n",
      "Requirement already satisfied: braceexpand in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from webdataset->-r requirements.txt (line 16)) (0.1.7)\n",
      "Requirement already satisfied: requests in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from wldhx.yadisk-direct->-r requirements.txt (line 18)) (2.32.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 8)) (0.44.0)\n",
      "Requirement already satisfied: Shapely in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from imgaug>=0.4.0->albumentations==0.5.2->-r requirements.txt (line 12)) (2.0.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from importlib-resources->hydra-core==1.1.0->-r requirements.txt (line 13)) (3.21.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (2.36.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->wldhx.yadisk-direct->-r requirements.txt (line 18)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->wldhx.yadisk-direct->-r requirements.txt (line 18)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->wldhx.yadisk-direct->-r requirements.txt (line 18)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests->wldhx.yadisk-direct->-r requirements.txt (line 18)) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (3.16.1)\n",
      "Requirement already satisfied: sympy in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (12.6.85)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from sympy->torch>=1.6.0->kornia==0.5.0->-r requirements.txt (line 15)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 8)) (3.2.2)\n",
      "Using cached kornia-0.5.0-py2.py3-none-any.whl (271 kB)\n",
      "Installing collected packages: kornia\n",
      "  Attempting uninstall: kornia\n",
      "    Found existing installation: kornia 0.7.3\n",
      "    Uninstalling kornia-0.7.3:\n",
      "      Successfully uninstalled kornia-0.7.3\n",
      "Successfully installed kornia-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kwy00/song/lama-with-refiner\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kornia in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (0.5.0)\n",
      "Collecting kornia\n",
      "  Using cached kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: kornia-rs>=0.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from kornia) (0.1.7)\n",
      "Requirement already satisfied: packaging in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from kornia) (24.2)\n",
      "Requirement already satisfied: torch>=1.9.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from kornia) (2.1.2)\n",
      "Requirement already satisfied: filelock in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from torch>=1.9.1->kornia) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.1->kornia) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from jinja2->torch>=1.9.1->kornia) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n",
      "Using cached kornia-0.7.3-py2.py3-none-any.whl (833 kB)\n",
      "Installing collected packages: kornia\n",
      "  Attempting uninstall: kornia\n",
      "    Found existing installation: kornia 0.5.0\n",
      "    Uninstalling kornia-0.5.0:\n",
      "      Successfully uninstalled kornia-0.5.0\n",
      "Successfully installed kornia-0.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kornia -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saicinpainting.training.trainers import make_training_model\n",
    "from saicinpainting.training.trainers import load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "#from lightning.pytorch.plugins import DDPPlugin\n",
    "\n",
    "from saicinpainting.training.trainers import make_training_model\n",
    "from saicinpainting.utils import register_debug_signal_handlers, handle_ddp_subprocess, handle_ddp_parent_process, \\\n",
    "    handle_deterministic_config\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path='./weights/big-lama'\n",
    "config_name='config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(os.path.join(config_path, config_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from saicinpainting.training.trainers.default import DefaultInpaintingTrainingModule\n",
    "from saicinpainting.training.trainers import make_training_model\n",
    "IMAGE_PREPROC_MEAN=0.5\n",
    "IMAGE_PREPROC_STD=0.225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ski_ssim\n",
    "import cv2\n",
    "def get_ssim_score(true, pred):\n",
    "    # 전체 RGB 이미지를 사용해 SSIM 계산 (channel_axis=-1)\n",
    "    ssim_value = ski_ssim(true, pred, channel_axis=-1, data_range=pred.max() - pred.min())\n",
    "    return ssim_value\n",
    "\n",
    "def get_masked_ssim_score(true, pred, mask):\n",
    "    # 손실 영역의 좌표에서만 RGB 채널별 픽셀 값 추출\n",
    "    true_masked_pixels = true[mask > 0]\n",
    "    pred_masked_pixels = pred[mask > 0]\n",
    "\n",
    "    # 손실 영역 픽셀만으로 SSIM 계산 (채널축 사용)\n",
    "    ssim_value = ski_ssim(\n",
    "        true_masked_pixels,\n",
    "        pred_masked_pixels,\n",
    "        channel_axis=-1,\n",
    "        data_range=pred.max() - pred.min()\n",
    "    )\n",
    "    return ssim_value\n",
    "\n",
    "def get_histogram_similarity(true, pred, cvt_color=cv2.COLOR_RGB2HSV):\n",
    "    # BGR 이미지를 HSV로 변환\n",
    "    true_hsv = cv2.cvtColor(true, cvt_color)\n",
    "    pred_hsv = cv2.cvtColor(pred, cvt_color)\n",
    "\n",
    "    # H 채널에서 히스토그램 계산 및 정규화\n",
    "    hist_true = cv2.calcHist([true_hsv], [0], None, [180], [0, 180])\n",
    "    hist_pred = cv2.calcHist([pred_hsv], [0], None, [180], [0, 180])\n",
    "    hist_true = cv2.normalize(hist_true, hist_true).flatten()\n",
    "    hist_pred = cv2.normalize(hist_pred, hist_pred).flatten()\n",
    "\n",
    "    # 히스토그램 간 유사도 계산 (상관 계수 사용)\n",
    "    similarity = cv2.compareHist(hist_true, hist_pred, cv2.HISTCMP_CORREL)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from saicinpainting.training.trainers.default import DefaultInpaintingTrainingModule\n",
    "\n",
    "\n",
    "def get_training_model_class(kind):\n",
    "    if kind == 'default':\n",
    "        return DefaultInpaintingTrainingModule\n",
    "\n",
    "    raise ValueError(f'Unknown trainer module {kind}')\n",
    "\n",
    "\n",
    "def make_training_model(config):\n",
    "    kind = config.training_model.kind\n",
    "    kwargs = dict(config.training_model)\n",
    "    kwargs.pop('kind')\n",
    "    kwargs['use_ddp'] = config.trainer.kwargs.get('accelerator', None) == 'ddp'\n",
    "\n",
    "    logging.info(f'Make training model {kind}')\n",
    "\n",
    "    cls = get_training_model_class(kind)\n",
    "    return cls(config, **kwargs)\n",
    "\n",
    "\n",
    "def load_checkpoint(train_config, path, map_location='cuda', strict=True):\n",
    "    model: torch.nn.Module = make_training_model(train_config)\n",
    "    state = torch.load(path, map_location=map_location)\n",
    "    model.load_state_dict(state['state_dict'], strict=strict)\n",
    "    model.on_load_checkpoint(state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18256), started 0:08:28 ago. (Use '!kill 18256' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bdd640fb06671ad1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bdd640fb06671ad1\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# 체크포인트 저장 경로와 규칙 정의\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"./checkpointss/\",           # 체크포인트 저장 디렉토리\n",
    "    filename=f'best2-{fold_idx=}-{SEED=}'+'-{epoch:02d}-{val_score:.4f}',  # 파일 이름 형식\n",
    "    save_top_k=1,                     # 가장 낮은 검증 손실을 기록한 3개만 저장\n",
    "    monitor=\"val_score\",               # 모니터링할 메트릭\n",
    "    mode=\"max\",                       # 손실이 작을수록 좋음\n",
    "    save_weights_only=True,          # 전체 모델 상태를 저장\n",
    "    verbose=True                      # 저장 시 메시지 출력\n",
    ")\n",
    "earlystopping_callback = EarlyStopping(monitor=\"val_score\",min_delta=1e-4, mode=\"max\", patience=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "trainer = Trainer(max_epochs=100, precision='32', callbacks=[checkpoint_callback,earlystopping_callback,], detect_anomaly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'  # 메모리 단편화 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saicinpainting.training.trainers import load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-04 19:49:34--  http://sceneparsing.csail.mit.edu/model/pytorch/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth\n",
      "sceneparsing.csail.mit.edu (sceneparsing.csail.mit.edu) 해석 중... 128.30.100.223\n",
      "다음으로 연결 중: sceneparsing.csail.mit.edu (sceneparsing.csail.mit.edu)|128.30.100.223|:80... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 95015426 (91M)\n",
      "저장 위치: ‘ade20k/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth.1’\n",
      "\n",
      "encoder_epoch_20.pt 100%[===================>]  90.61M  1.15MB/s    / 53s      \n",
      "\n",
      "2024-12-04 19:50:28 (1.73 MB/s) - ‘ade20k/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth.1’ 저장함 [95015426/95015426]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!mkdir -p ade20k/ade20k-resnet50dilated-ppm_deepsup/\n",
    "!wget -P ade20k/ade20k-resnet50dilated-ppm_deepsup/ http://sceneparsing.csail.mit.edu/model/pytorch/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning\n",
    "class placemodel(lightning.pytorch.LightningModule):\n",
    "  def __init__(self,  image_mean=IMAGE_PREPROC_MEAN, image_std=IMAGE_PREPROC_STD):\n",
    "    super().__init__()\n",
    "    self.training = True\n",
    "    checkpoint_path = \"/home/kwy00/song/lama-with-refiner/weights/big-lama/models/best.ckpt\"\n",
    "    self.model_1 = load_checkpoint(config,checkpoint_path,strict=False)\n",
    "    self.model_1.eval()\n",
    "    self.model_2 = model_2\n",
    "    self.image_mean=image_mean\n",
    "    self.image_std=image_std\n",
    "\n",
    "  def forward(self, images_gray_masked):\n",
    "      if self.training == True:\n",
    "\n",
    "\n",
    "        images_gray_masked['image'] = torch.cat([images_gray_masked['image'],images_gray_masked['image'],images_gray_masked['image']],dim=1)\n",
    "        with torch.no_grad():\n",
    "          igm = self.model_1(images_gray_masked)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        rgb_images = igm['inpainted']\n",
    "        rgb_onechannel = rgb_images[:, 0:1, :, :]\n",
    "\n",
    "        mask_min =rgb_onechannel.min()\n",
    "        mask_max =rgb_onechannel.max()\n",
    "\n",
    "           # 정규화 해제하여 원래 값 복원\n",
    "        images_gray_restored= rgb_onechannel * (mask_max - mask_min + 1e-8) + mask_min\n",
    "\n",
    "\n",
    "\n",
    "        images_restored = self.model_2(rgb_onechannel)\n",
    "        #self.logger.experiment.add_images('Training/Model2 output', images_restored, self.global_step)\n",
    "        return rgb_onechannel, images_restored\n",
    "      else :\n",
    "        with torch.no_grad():\n",
    "\n",
    "            images_gray_masked['image'] = torch.cat([images_gray_masked['image'],images_gray_masked['image'],images_gray_masked['image']],dim=1)\n",
    "            #print(f\"mask_shape:{images_gray_masked['mask'].shape}\")\n",
    "            #self.logger.experiment.add_images('Testing/Model1 mask', images_gray_masked['mask'], self.global_step)\n",
    "            igm = self.model_1(images_gray_masked)\n",
    "            rgb_images = igm['inpainted']\n",
    "            #self.logger.experiment.add_images('Testing/Model1 output', rgb_images[:, 0:1, :, :], self.global_step)\n",
    "            rgb_onechannel = rgb_images[:, 0:1, :, :]\n",
    "            images_gray_restored = rgb_onechannel\n",
    "\n",
    "            mask_min =images_gray_restored.min()\n",
    "            mask_max =images_gray_restored.max()\n",
    "\n",
    "           # 정규화 해제하여 원래 값 복원\n",
    "            images_gray_restored= images_gray_restored * (mask_max - mask_min + 1e-8) + mask_min\n",
    "\n",
    "            images_restored = self.model_2(images_gray_restored)\n",
    "            #self.logger.experiment.add_images('Testing/Model2 output', images_restored, self.global_step)\n",
    "        return rgb_onechannel, images_restored\n",
    "\n",
    "\n",
    "  def unnormalize(self, output, round=False):\n",
    "        image_restored = ((output*self.image_std+self.image_mean)*255).clamp(0,255)\n",
    "        if round:\n",
    "            image_restored = torch.round(image_restored)\n",
    "        return image_restored\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            verbose=True\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_score\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "        self.training = True\n",
    "        opt = self.optimizers()\n",
    "        opt.zero_grad()\n",
    "        #batch['masks'] = (batch['masks'] -batch['masks'].min()) / (batch['masks'].max() - batch['masks'].min() + 1e-8)\n",
    "        batch['images_gray_masked'] = (batch['images_gray_masked'] -batch['images_gray_masked'].min()) / (batch['images_gray_masked'].max() - batch['images_gray_masked'].min() + 1e-8)\n",
    "        batch['images_gray'] = (batch['images_gray'] -batch['images_gray'].min()) / (batch['images_gray'].max() -batch['images_gray'].min() + 1e-8)\n",
    "        #batch['images_gt'] = (batch['images_gt'] -batch['images_gt'].min()) / (batch['images_gt'].max() -batch['images_gt'].min() + 1e-8)\n",
    "\n",
    "        masks, images_gray_masked, images_gray, images_gt = batch['masks'], batch['images_gray_masked'], batch['images_gray'], batch['images_gt']\n",
    "        batch2 ={}\n",
    "\n",
    "        batch2['image'] = batch['images_gray']\n",
    "        batch2['mask'] = batch['masks']\n",
    "        batch2['mask'] = batch2['mask'].unsqueeze(1)\n",
    "\n",
    "\n",
    "        images_gray_restored, images_restored = self(batch2)\n",
    "\n",
    "        mask_min =images_gray_restored.min()\n",
    "        mask_max =images_gray_restored.max()\n",
    "\n",
    "        # 정규화 해제하여 원래 값 복원\n",
    "        images_gray_restored= images_gray_restored * (mask_max - mask_min + 1e-8) + mask_min\n",
    "\n",
    "\n",
    "        mask_min =images_gray.min()\n",
    "        mask_max =images_gray.max()\n",
    "\n",
    "        # 정규화 해제하여 원래 값 복원\n",
    "        images_gray = images_gray * (mask_max - mask_min + 1e-8) + mask_min\n",
    "\n",
    "        loss_pixel_gray = F.l1_loss(images_gray, images_gray_restored, reduction='mean') * 0.3 + F.mse_loss(images_gray, images_gray_restored, reduction='mean') * 0.7\n",
    "        loss_pixel = F.l1_loss(images_gt, images_restored, reduction='mean') * 0.3 + F.mse_loss(images_gt, images_restored, reduction='mean') * 0.7\n",
    "        loss = loss_pixel_gray * 0.3 + loss_pixel * 0.7\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=False)\n",
    "        self.log(\"train_loss_pixel_gray\", loss_pixel_gray, on_step=True, on_epoch=False)\n",
    "        self.log(\"train_loss_pixel\", loss_pixel, on_step=True, on_epoch=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "      self.training = True\n",
    "      batch['images_gray_masked'] = (batch['images_gray_masked'] -batch['images_gray_masked'].min()) / (batch['images_gray_masked'].max() - batch['images_gray_masked'].min() + 1e-8)\n",
    "      #batch['images_gt'] = (batch['images_gt'] -batch['images_gt'].min()) / (batch['images_gt'].max() -batch['images_gt'].min() + 1e-8)\n",
    "\n",
    "      masks, images_gray_masked, images_gt = batch['masks'], batch['images_gray_masked'], batch['images_gt']\n",
    "\n",
    "      batch2 = {}\n",
    "      batch2['image'] = batch['images_gray_masked']\n",
    "      batch2['mask'] = batch['masks']\n",
    "      batch2['mask'] = batch2['mask'].unsqueeze(1)  # (Batch, 1, Height, Width)\n",
    "\n",
    "      images_gray_restored, images_restored = self(batch2)\n",
    "\n",
    "      images_gt, images_restored = self.unnormalize(images_gt, round=True), self.unnormalize(images_restored, round=True)\n",
    "      masks_np = masks.detach().cpu().numpy()\n",
    "      images_gt_np = images_gt.detach().cpu().permute(0,2,3,1).float().numpy().astype(np.uint8)\n",
    "      images_restored_np = images_restored.detach().cpu().permute(0,2,3,1).float().numpy().astype(np.uint8)\n",
    "      total_ssim_score = 0\n",
    "      masked_ssim_score = 0\n",
    "      hist_sim_score = 0\n",
    "      for image_gt_np, image_restored_np, mask_np in zip(images_gt_np, images_restored_np, masks_np):\n",
    "          total_ssim_score += get_ssim_score(image_gt_np, image_restored_np) / len(images_gt)\n",
    "          masked_ssim_score += get_masked_ssim_score(image_gt_np, image_restored_np, mask_np)/ len(images_gt)\n",
    "          hist_sim_score += get_histogram_similarity(image_gt_np, image_restored_np, cv2.COLOR_RGB2HSV)/ len(images_gt)\n",
    "      score = total_ssim_score * 0.2 + masked_ssim_score * 0.4 + hist_sim_score * 0.4\n",
    "      self.log(f\"val_score\", score, on_step=False, on_epoch=True)\n",
    "      self.log(f\"val_total_ssim_score\", total_ssim_score, on_step=False, on_epoch=True)\n",
    "      self.log(f\"val_masked_ssim_score\", masked_ssim_score, on_step=False, on_epoch=True)\n",
    "      self.log(f\"val_hist_sim_score\", hist_sim_score, on_step=False, on_epoch=True)\n",
    "\n",
    "\n",
    "      return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def predict_step(self, batch, batch_idx):\n",
    "        self.training = False\n",
    "        batch['images_gray_masked'] = (batch['images_gray_masked'] -batch['images_gray_masked'].min()) / (batch['images_gray_masked'].max() - batch['images_gray_masked'].min() + 1e-8)\n",
    "        batch['mask'] = (batch['mask'] -batch['mask'].min()) / (batch['mask'].max() - batch['mask'].min() + 1e-8)\n",
    "        images_gray_masked = batch['images_gray_masked']\n",
    "        batch2 ={}\n",
    "        batch2['image'] = images_gray_masked\n",
    "\n",
    "        #batch['mask'] = batch['mask'][:, 0:1, :, :]\n",
    "        batch2['mask'] = batch['mask'].unsqueeze(1)\n",
    "\n",
    "        images_gray_restored, images_restored = self(batch2)\n",
    "\n",
    "\n",
    "        # 기존 정규화에서 사용한 min, max 값\n",
    "\n",
    "        #self.logger.experiment.add_images('Training/Model1 images_restored', images_restored, self.global_step)\n",
    "        images_restored = self.unnormalize(images_restored, round=True)\n",
    "\n",
    "        #self.logger.experiment.add_images('Training/Model1 unnormalize', images_restored, self.global_step)\n",
    "        images_restored_np = images_restored.detach().cpu().permute(0,2,3,1).float().numpy().astype(np.uint8)\n",
    "        #self.logger.experiment.add_images('Training/Model1 images_restored', images_restored_np, self.global_step)\n",
    "        return images_restored_np\n",
    "#색칠만 이상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "model_2 = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b3\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PermissionError: Unable to create directory at /group-volume/User-Driven-Content-Generation/r.suvorov/inpainting/experiments/r.suvorov_2021-04-30_14-41-12_train_simple_pix2pix2_gap_sdpl_novgg_large_b18_ffc075_batch8x15/samples. Using fallback path.\n",
      "Loading weights for net_encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /home/kwy00/song/lama-with-refiner/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                            | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | model_1 | DefaultInpaintingTrainingModule | 132 M  | eval \n",
      "1 | model_2 | Unet                            | 13.2 M | train\n",
      "--------------------------------------------------------------------\n",
      "71.1 M    Trainable params\n",
      "74.8 M    Non-trainable params\n",
      "145 M     Total params\n",
      "583.786   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2738/2738 [52:42<00:00,  0.87it/s, v_num=0]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_score improved. New best score: 0.516\n",
      "Epoch 0, global step 2738: 'val_score' reached 0.51579 (best 0.51579), saving model to '/home/kwy00/song/lama-with-refiner/checkpointss/best2-fold_idx=0-SEED=42-epoch=00-val_score=0.5158.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2738/2738 [52:09<00:00,  0.87it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_score improved by 0.028 >= min_delta = 0.0001. New best score: 0.543\n",
      "Epoch 1, global step 5476: 'val_score' reached 0.54347 (best 0.54347), saving model to '/home/kwy00/song/lama-with-refiner/checkpointss/best2-fold_idx=0-SEED=42-epoch=01-val_score=0.5435.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   3%|▎         | 89/2738 [01:32<46:01,  0.96it/s, v_num=0]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwy00/anaconda3/envs/song/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(placemodel(), train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PermissionError: Unable to create directory at /group-volume/User-Driven-Content-Generation/r.suvorov/inpainting/experiments/r.suvorov_2021-04-30_14-41-12_train_simple_pix2pix2_gap_sdpl_novgg_large_b18_ffc075_batch8x15/samples. Using fallback path.\n",
      "Loading weights for net_encoder\n"
     ]
    }
   ],
   "source": [
    "lit_ir_model = placemodel.load_from_checkpoint(\n",
    "\n",
    "    '/home/kwy00/song/lama-with-refiner/checkpointss/best2-fold_idx=0-SEED=42-epoch=01-val_score=0.5435.ckpt',\n",
    "    model_2=model_2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 7/7 [00:09<00:00,  0.77it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(lit_ir_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dir = os.path.join(SUBMISSON_DATA_DIR, EXPERIMENT_NAME)\n",
    "submission_file = f'{SUBMISSON_DATA_DIR}/{EXPERIMENT_NAME}.zip'\n",
    "os.makedirs(submission_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    image_pred = Image.fromarray(predictions[idx])\n",
    "    image_pred.save(os.path.join(submission_dir, row['image']), \"PNG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
